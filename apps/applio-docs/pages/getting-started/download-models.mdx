import { Steps } from 'nextra/components'
import { Cards } from 'nextra/components'
import { Tabs } from 'nextra/components'

# Download models

<Steps>

### Automatic Download

To download a voice model, go to the **‚Äúdownload‚Äù** section and enter the link to the file. Now you can search for models from Applio by simply entering the character name to search in the **"Search Model"** section, then copy the model link or download it.

Applio support links from the following platforms:

- ‚úÖ **Google Drive**
- ‚úÖ **Hugging Face**
- ‚úÖ **Discord**
- ‚úÖ **Applio Web**
- ‚úÖ **Yandex**
- ‚úÖ **Pixeldrain**
- ‚úÖ **Mediafire**
- ‚ùå **Mega**
 
### Manual Upload

In the same download section, you can see a box to upload files, simply unzip your `.zip` file and drop file by file.
</Steps>


# Inferencing

Inference is a **simple** process that you can do in **three easy steps**, where the program takes an input audio and transforms it into the voice it has been trained on. Replicating the vocal characteristics, intonation, and style of the original voice.

![](/Inference.png)

<Tabs items={['Single', 'Batch']} defaultIndex="0">
  <Tabs.Tab>
  <Steps>
  ## Making a single inference
  ### Step 1: Select your model

Simply select in the boxes the `.pth` and `.index` file of the downloaded/trained model. If not displayed refresh the model list.

### Step 2: Load your audio

As the first step, select and upload the audio file in the corresponding box.

### Step 3: Make the inference! üéâ

now you are ready to perform your inference, just click convert and you will get your result. The processing time will depend on the speed of your CPU/GPU.

</Steps>
- **if you have any error, check that the audio you upload *does not* contain special characters or spaces in its name**
</Tabs.Tab>
  <Tabs.Tab> <Steps>
   ## Making a batch inference
  ### Step 1: Place your audio files in a folder

Copy and paste the path into the Input Folder, if you‚Äôd like, you can also specify the output path for the converted audios in the Output Folder.

### Step 2: Select the models

Click the Refresh button at the top right and select the downloaded/uploaded files in the Voice model and index file box.

### Step 3: Make the inference! üéâ

again you are ready to perform your inference, just click convert and you will get your result. The processing time will depend on the speed of your CPU/GPU.


</Steps>
- **if you have any error, check that the audio you upload *does not* contain special characters or spaces in its name**
</Tabs.Tab>
</Tabs>
export function FAQBox({ title, children }) {
  return (
    <details
      closed
      className="last-of-type:mb-0 rounded-lg bg-neutral-50 dark:bg-neutral-800 p-2 mt-4"
    >
      <summary>
        <strong className="text-lg">{title}</strong>
      </summary>
      <div className="nx-p-2">{children}</div>
    </details>
  )
}

<FAQBox title="Advanced Settings section">
Applio has an ‚Äúadvanced options‚Äù section which allows you to modify several settings for your result, this box focuses on describe each one of them:

- **Export Format**: Select the format to export the audio.
- **Split Audio**: Basically cuts the audio into parts to make the inference by parts and then joins them together.
- **Autotune**: Apply a soft autotune to your inferences, recommended for singing conversions.
- **Clean Audio**: Clean your audio output using noise detection algorithms, recommended for speaking audios.
- **Upscale Audio**: Upscale the audio to a higher quality, recommended for low-quality audios.
- **Clean Strenght**: The more you increase it the more it will clean up, but it will be more compressed.
- **Pitch**: Adjust the tone of the model, for male it is - and female it is +. For male to female is -12 and female to male is +12.
- **Filter Radius**: Applies respiration filtering to the results, the value represents the filter radius and respiration reduction to avoid artifacts.
- **Search Feature Ratio**: It is the one in charge of controlling the index, the larger the ratio, the more single the dataset but it can result in artifacts, so it is better to leave it as it is by default.
- **Volume Envelope**: Substitute or blend with the volume envelope of the output.
- **Protec Voiceless Consonants**: Safeguard distinct consonants and breathing sounds to prevent electro-acoustic tearing and other artifacts.
- **Hop Length**: Denotes the duration it takes for the system to transition to a significant pitch change. Smaller hop lengths require more time for inference and training but tend to yield higher pitch accuracy.
- **Pitch extraction algorithm**: Select between rvmpe, crepe or other.
- **Embedder Model**: select the Embedder model (contentvec, japanese-hubert-base, chinese-hubert-large or custom).
- **Formant Shifting:** used for male to female and vice-versa convertions. Here you can adjust the **Quefrency for formant shifting** and the **Timbre for formant shifting**.
- **Post-Process:** post-process the audio to apply effects to the output. Here you can modify the following:
   - **Reverb:** you can set the Reverb Room Size, Reverb Damping, Reverb Wet Gain, Reverb Dry Gain, Reverb Width and the Reverb Freeze Mode.
   - **Pitch Shift:** Set the pitch shift semitones.
   - **Limiter:** you can set the Limiter Threshold dB and the Limiter Release Time.
   - **Gain:** Set the gain dB.
   - **Distortion:** Set the distortion gain.
   - **Chorus:** you can set the Chorus Rate Hz, chorus Depth, chorus Center Delay ms, chorus Feedback and the Chorus Mix.
   - **Bitcrush:** apply bitcrush to the audio.
   - **Clipping:** Set the clipping threshold.
   - **Compressor:** you can set the Compressor Threshold dB, Compressor Ratio, Compressor Attack ms and the Compressor Release ms.
   - **Delay:** you can set the Delay Seconds, Delay Feedback and the Delay Mix.
</FAQBox>


<FAQBox title="Tips for making inferences">
What should I do if my output audio sounds robotic?


- **Look for better quality audio.**
- **In case of training, your voice model needs more [training](/getting-started/training) or is overtraining.**
- **Remove the reverb, double vocals and noise from your acapella, you can check the [UVR 5 or MVSEP guide](/guides/audio-isolating/uvr).**
- **The dataset of your model contained noise, you need to [clean the dataset](/guides/create-datasets/create-datasets).**
- **Try advanced settings.**
</FAQBox>

