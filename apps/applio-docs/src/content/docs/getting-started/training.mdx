---
title: "Training a Voice Model"
description: "A step-by-step guide to training a high-quality voice model in Applio."
sidebar:
  order: 6
---

import { Aside, Steps, FileTree } from '@astrojs/starlight/components';

**Training** is the process where Applio learns to replicate a voice from a dataset of audio files. This guide will walk you through each step of the training process, from preparing your dataset to exporting your final model.

<Aside type="note">
  If you don't have a powerful local GPU, you can use our [Google Colab Guide](/getting-started/google-colab-guide/) to train your model in the cloud.
</Aside>

### Step 1: Prepare Your Dataset

The first and most important step is to prepare a high-quality audio dataset.

-   **Duration:** Aim for 10-30 minutes of clean audio.
-   **Format:** Your audio files must be in a lossless format, such as `.wav` or `.flac`.
-   **Quality:** The audio should be free of background noise, reverb, and other artifacts.

For a detailed guide on creating a high-quality dataset, please see our [Dataset Creation Guide](/guides/how-create-datasets/).

Once your dataset is ready, you need to place it in the `applio/assets/datasets` directory. Create a new folder inside this directory for your model.

#### Multi-Speaker Models (Optional)

If you want to train a model with multiple speakers, create a subfolder for each speaker inside your model's dataset folder. The speaker folders must be named numerically, starting from `0`.

<FileTree>
- applio/assets/datasets/your-model-name/
  - 0/
    - speaker0-audio1.wav
    - speaker0-audio2.wav
  - 1/
    - speaker1-audio1.wav
    - speaker1-audio2.wav
</FileTree>

### Step 2: Pre-process the Dataset

Now it's time to pre-process your dataset.

<Steps>
1.  In the **Train** tab of Applio, enter a name for your model.
2.  Select the correct sample rate for your audio files (`32k`, `40k`, or `48k`).
3.  Click the **Pre-process Dataset** button.
</Steps>

### Step 3: Extract Features

Next, you need to extract the features from your pre-processed dataset.

<Steps>
1.  **Choose a Pitch Extraction Algorithm:** We recommend using **RMVPE** for the best results.
2.  **Select an Embedder Model:** Make sure to choose the correct embedder for your model.
3.  Click the **Extract Features** button.
</Steps>

This process will take some time. You can monitor the progress in the command line window.

### Step 4: Train the Model and Index

This is the final and most time-consuming step.

<Steps>
1.  **Set the "Save Every Epoch" Value:** This determines how often the model is saved. A value between 10 and 50 is recommended.
2.  **Set the "Total Epochs":** This is the total number of times the model will train on the entire dataset. A good starting point is 200-400 epochs, but you should use [TensorBoard](/getting-started/tensorboard) to monitor your model's progress and decide when to stop.
3.  **Set the "Batch Size":** This depends on your GPU's VRAM. For an 8GB GPU, a batch size of 6-8 is a good starting point.
4.  Click the **Train Model** button.
5.  Once the model training is complete, click the **Train Index** button.
</Steps>

![A screenshot of the training configuration section in Applio.](/images/training.png)

### Step 5: Export Your Model

Your trained models are saved in the `logs` folder. You can also export them directly from the Applio interface.

<Steps>
1.  Go to the **Export Model** section in the **Train** tab.
2.  Click the **Refresh** button.
3.  Select the `.pth` file and the corresponding `.index` file for your model.
4.  Click the **Export Model** button.
</Steps>

<Aside type="tip">
  You can often get better results by using a [pre-trained model](/getting-started/pretrained) as a starting point for your training.
</Aside>